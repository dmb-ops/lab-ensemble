{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample DataFrame creation\n",
    "data = {\n",
    "    'PassengerId': ['0001_01', '0002_01', '0003_01', '0003_02', '0004_01'],\n",
    "    'HomePlanet': ['Europa', 'Earth', 'Europa', 'Europa', 'Earth'],\n",
    "    'CryoSleep': [False, False, False, False, False],\n",
    "    'Cabin': ['B/0/P', 'F/0/S', 'A/0/S', 'A/0/S', 'F/1/S'],\n",
    "    'Destination': ['TRAPPIST-1e'] * 5,\n",
    "    'Age': [39.0, 24.0, 58.0, 33.0, 16.0],\n",
    "    'VIP': [False, False, True, False, False],\n",
    "    'RoomService': [0.0, 109.0, 43.0, 0.0, 303.0],\n",
    "    'FoodCourt': [0.0, 9.0, 3576.0, 1283.0, 70.0],\n",
    "    'ShoppingMall': [0.0, 25.0, 0.0, 371.0, 151.0],\n",
    "    'Spa': [0.0, 549.0, 6715.0, 3329.0, 565.0],\n",
    "    'VRDeck': [0.0, 44.0, 49.0, 193.0, 2.0],\n",
    "    'Transported': [False, True, False, False, True]\n",
    "}\n",
    "    \n",
    "df = pd.DataFrame(data) \n",
    "\n",
    "\n",
    "df['CryoSleep'] = df['CryoSleep'].astype(int)\n",
    "df['VIP'] = df['VIP'].astype(int)\n",
    "df['Transported'] = df['Transported'].astype(int)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "df = pd.get_dummies(df, columns=['HomePlanet', 'Destination', 'Cabin'], drop_first=True)\n",
    "\n",
    "# Drop identifiers\n",
    "df = df.drop(columns=['PassengerId'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['Transported'])\n",
    "y = df['Transported']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Selected Features:\n",
      " Index(['Age', 'RoomService', 'HomePlanet_Europa', 'Cabin_F/0/S',\n",
      "       'Cabin_F/1/S'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/baseroot2/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [0] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/opt/anaconda3/envs/baseroot2/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Top Selected Features:\\n\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1328291543.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mX_train, X_test, y_train, y_test = train_test_split(\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_selected, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, selected_features\n",
    "\n",
    "X_train, X_test, y_train, y_test, selected_features = preprocess_and_split(df)\n",
    "\n",
    "print(\"Selected Features:\", selected_features.tolist())\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1731248463.py, line 30)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpasting_clf.fit(X_train, y_train)\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_bagging_pasting(X_train, X_test, y_train, y_test):\n",
    "    # Base estimator\n",
    "    base_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Bagging classifier (with replacement)\n",
    "    bagging_clf = BaggingClassifier(\n",
    "        estimator=base_tree,\n",
    "        n_estimators=10,\n",
    "        max_samples=0.8,\n",
    "        bootstrap=True,  # Sampling WITH replacement\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    y_pred_bagging = bagging_clf.predict(X_test)\n",
    "    acc_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "    \n",
    "pasting_clf = BaggingClassifier(\n",
    "        estimator=base_tree,\n",
    "        n_estimators=10,\n",
    "        max_samples=0.8,\n",
    "        bootstrap=False,  # Sampling WITHOUT replacement\n",
    "        random_state=42\n",
    "    )\n",
    "    pasting_clf.fit(X_train, y_train)\n",
    "    y_pred_pasting = pasting_clf.predict(X_test)\n",
    "    acc_pasting = accuracy_score(y_test, y_pred_pasting)\n",
    "\n",
    "    print(f\"Bagging Accuracy: {acc_bagging:.2f}\")\n",
    "    print(f\"Pasting Accuracy: {acc_pasting:.2f}\")\n",
    "\n",
    "    return bagging_clf, pasting_clf\n",
    "\n",
    "bagging_model, pasting_model = train_bagging_pasting(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def train_random_forest(X_train, X_test, y_train, y_test):\n",
    "    # Initialize Random Forest\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        random_state=42,\n",
    "        n_jobs=-1  # Use all CPU cores\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Random Forest Accuracy: {accuracy:.2f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return rf_clf\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rf_model = train_random_forest(\u001b[43mX_train\u001b[49m, X_test, y_train, y_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "rf_model = train_random_forest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gb_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     gb_acc = accuracy_score(y_test, gb_pred)\n\u001b[32m     14\u001b[39m     results[\u001b[33m'\u001b[39m\u001b[33mGradient Boosting\u001b[39m\u001b[33m'\u001b[39m] = gb_acc\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGradient Boosting Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mgb_acc\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'gb_acc' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_boosting_models(X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "\n",
    "    # Gradient Boosting\n",
    "    gb_clf = GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    gb_pred = gb_clf.predict(X_test)\n",
    "    gb_acc = accuracy_score(y_test, gb_pred)\n",
    "    results['Gradient Boosting'] = gb_acc\n",
    "\n",
    "print(f\"Gradient Boosting Accuracy: {gb_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (916596241.py, line 4)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mada_clf.fit(X_train, y_train)\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    ada_pred = ada_clf.predict(X_test)\n",
    "    ada_acc = accuracy_score(y_test, ada_pred)\n",
    "    results['AdaBoost'] = ada_acc\n",
    "\n",
    "    # Print results\n",
    "    print(f\"AdaBoost Accuracy: {ada_acc:.2f}\")\n",
    "\n",
    "    return gb_clf, ada_clf, results\n",
    "\n",
    "print(f\"AdaBoost Accuracy: {ada_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model_scores = {\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBagging\u001b[39m\u001b[33m'\u001b[39m: accuracy_score(\u001b[43my_test\u001b[49m, bagging_model.predict(X_test)),\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPasting\u001b[39m\u001b[33m'\u001b[39m: accuracy_score(y_test, pasting_model.predict(X_test)),\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m: accuracy_score(y_test, rf_model.predict(X_test)),\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mGradient Boosting\u001b[39m\u001b[33m'\u001b[39m: boost_results[\u001b[33m'\u001b[39m\u001b[33mGradient Boosting\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAdaBoost\u001b[39m\u001b[33m'\u001b[39m: boost_results[\u001b[33m'\u001b[39m\u001b[33mAdaBoost\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m }\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Sort by accuracy\u001b[39;00m\n\u001b[32m     10\u001b[39m sorted_scores = \u001b[38;5;28msorted\u001b[39m(model_scores.items(), key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m], reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "model_scores = {\n",
    "    'Bagging': accuracy_score(y_test, bagging_model.predict(X_test)),\n",
    "    'Pasting': accuracy_score(y_test, pasting_model.predict(X_test)),\n",
    "    'Random Forest': accuracy_score(y_test, rf_model.predict(X_test)),\n",
    "    'Gradient Boosting': boost_results['Gradient Boosting'],\n",
    "    'AdaBoost': boost_results['AdaBoost']\n",
    "}\n",
    "\n",
    "# Sort by accuracy\n",
    "sorted_scores = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n‚úÖ Model Performance Summary:\")\n",
    "for name, acc in sorted_scores:\n",
    "    print(f\"{name}: {acc:.2f}\")\n",
    "\n",
    "best_model = sorted_scores[0][0]\n",
    "print(f\"\\nüèÜ Best performing model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
